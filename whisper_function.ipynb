{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook sample"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:26:02.062177Z",
     "start_time": "2024-10-19T15:24:28.112600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install ffmpeg using conda\n",
    "!conda install -c conda-forge ffmpeg -y"
   ],
   "id": "3a9dcff58ba7db71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 4.10.3\r\n",
      "  latest version: 24.9.2\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - ffmpeg\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  aom                pkgs/main/osx-64::aom-3.6.0-hcec6c5f_0\r\n",
      "  cairo              pkgs/main/osx-64::cairo-1.16.0-h3ce6f7e_5\r\n",
      "  dav1d              conda-forge/osx-64::dav1d-1.2.1-h0dc2134_0\r\n",
      "  expat              conda-forge/osx-64::expat-2.6.3-hac325c4_0\r\n",
      "  ffmpeg             pkgs/main/osx-64::ffmpeg-6.1.1-h931e7ea_0\r\n",
      "  fontconfig         pkgs/main/osx-64::fontconfig-2.14.1-hb0a0c50_2\r\n",
      "  fribidi            conda-forge/osx-64::fribidi-1.0.10-hbcb3906_0\r\n",
      "  gdk-pixbuf         pkgs/main/osx-64::gdk-pixbuf-2.42.10-h46256e1_1\r\n",
      "  giflib             conda-forge/osx-64::giflib-5.2.2-h10d778d_0\r\n",
      "  graphite2          pkgs/main/osx-64::graphite2-1.3.14-he9d5cce_1\r\n",
      "  harfbuzz           pkgs/main/osx-64::harfbuzz-4.3.0-hffc734d_2\r\n",
      "  lame               conda-forge/osx-64::lame-3.100-hb7f2c08_1003\r\n",
      "  leptonica          pkgs/main/osx-64::leptonica-1.82.0-hf15457e_2\r\n",
      "  libarchive         pkgs/main/osx-64::libarchive-3.6.2-h29ab7a1_3\r\n",
      "  libexpat           conda-forge/osx-64::libexpat-2.6.3-hac325c4_0\r\n",
      "  libogg             conda-forge/osx-64::libogg-1.3.5-hfdf4475_0\r\n",
      "  libopus            conda-forge/osx-64::libopus-1.3.1-hc929b4f_1\r\n",
      "  librsvg            pkgs/main/osx-64::librsvg-2.54.4-h2f8da11_3\r\n",
      "  libtheora          conda-forge/osx-64::libtheora-1.1.1-hfdf4475_1006\r\n",
      "  libvorbis          conda-forge/osx-64::libvorbis-1.3.7-h046ec9c_0\r\n",
      "  libvpx             pkgs/main/osx-64::libvpx-1.13.1-hcec6c5f_0\r\n",
      "  libwebp            pkgs/main/osx-64::libwebp-1.3.2-hf6ce154_0\r\n",
      "  openh264           pkgs/main/osx-64::openh264-2.1.1-h8346a28_0\r\n",
      "  pango              pkgs/main/osx-64::pango-1.50.7-h80fe9ab_0\r\n",
      "  pixman             pkgs/main/osx-64::pixman-0.40.0-h9ed2024_1\r\n",
      "  tesseract          pkgs/main/osx-64::tesseract-5.2.0-he9d5cce_0\r\n",
      "\r\n",
      "The following packages will be UPDATED:\r\n",
      "\r\n",
      "  openssl              pkgs/main::openssl-3.0.15-h46256e1_0 --> conda-forge::openssl-3.3.2-hd23fc13_0\r\n",
      "\r\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\r\n",
      "\r\n",
      "  ca-certificates    pkgs/main::ca-certificates-2024.9.24-~ --> conda-forge::ca-certificates-2024.8.30-h8857fd0_0\r\n",
      "  certifi            pkgs/main/osx-64::certifi-2024.8.30-p~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0\r\n",
      "\r\n",
      "The following packages will be DOWNGRADED:\r\n",
      "\r\n",
      "  gettext                                 0.21.0-h4e8c18a_2 --> 0.21.0-he85b6c0_1\r\n",
      "  libxml2                                 2.13.1-h6070cd6_2 --> 2.10.4-h45904e2_2\r\n",
      "\r\n",
      "\r\n",
      "Preparing transaction: done\r\n",
      "Verifying transaction: done\r\n",
      "Executing transaction: done\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:40:03.418959Z",
     "start_time": "2024-10-19T15:39:40.052624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "# Install ffmpeg without sudo\n",
    "!apt update && apt install -y ffmpeg"
   ],
   "id": "7df9140457caed5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\r\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/y9/ynp6f9z95sv1f6g_g09bwmkr0000gn/T/pip-req-build-d7skx3jv\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/y9/ynp6f9z95sv1f6g_g09bwmkr0000gn/T/pip-req-build-d7skx3jv\r\n",
      "  Resolved https://github.com/openai/whisper.git to commit 25639fc17ddc013d56c594bfbf7644f2185fad84\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting numba (from openai-whisper==20240930)\r\n",
      "  Using cached numba-0.58.1-cp38-cp38-macosx_10_9_x86_64.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: numpy in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from openai-whisper==20240930) (1.24.3)\r\n",
      "Collecting torch (from openai-whisper==20240930)\r\n",
      "  Using cached torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl.metadata (25 kB)\r\n",
      "Collecting tqdm (from openai-whisper==20240930)\r\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting more-itertools (from openai-whisper==20240930)\r\n",
      "  Using cached more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\r\n",
      "Collecting tiktoken (from openai-whisper==20240930)\r\n",
      "  Using cached tiktoken-0.7.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper==20240930)\r\n",
      "  Using cached llvmlite-0.41.1-cp38-cp38-macosx_10_9_x86_64.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: importlib-metadata in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from numba->openai-whisper==20240930) (7.0.1)\r\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper==20240930)\r\n",
      "  Using cached regex-2024.9.11-cp38-cp38-macosx_10_9_x86_64.whl.metadata (40 kB)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\r\n",
      "Collecting filelock (from torch->openai-whisper==20240930)\r\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from torch->openai-whisper==20240930) (4.11.0)\r\n",
      "Collecting sympy (from torch->openai-whisper==20240930)\r\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch->openai-whisper==20240930)\r\n",
      "  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: jinja2 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from torch->openai-whisper==20240930) (3.1.4)\r\n",
      "Collecting fsspec (from torch->openai-whisper==20240930)\r\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from importlib-metadata->numba->openai-whisper==20240930) (3.20.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yuiwatanabe/opt/anaconda3/envs/telegram_bot/lib/python3.8/site-packages (from jinja2->torch->openai-whisper==20240930) (2.1.3)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch->openai-whisper==20240930)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Using cached more_itertools-10.5.0-py3-none-any.whl (60 kB)\r\n",
      "Using cached numba-0.58.1-cp38-cp38-macosx_10_9_x86_64.whl (2.6 MB)\r\n",
      "Using cached tiktoken-0.7.0-cp38-cp38-macosx_10_9_x86_64.whl (961 kB)\r\n",
      "Using cached torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\r\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\r\n",
      "Using cached llvmlite-0.41.1-cp38-cp38-macosx_10_9_x86_64.whl (31.0 MB)\r\n",
      "Using cached regex-2024.9.11-cp38-cp38-macosx_10_9_x86_64.whl (287 kB)\r\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\r\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\r\n",
      "Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\r\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Building wheels for collected packages: openai-whisper\r\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=dea4ffbf087021009aaae54facca5a290263f6735b9529f1344d27c2989c688a\r\n",
      "  Stored in directory: /private/var/folders/y9/ynp6f9z95sv1f6g_g09bwmkr0000gn/T/pip-ephem-wheel-cache-uwlg9gmw/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\r\n",
      "Successfully built openai-whisper\r\n",
      "Installing collected packages: mpmath, tqdm, sympy, regex, networkx, more-itertools, llvmlite, fsspec, filelock, torch, tiktoken, numba, openai-whisper\r\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.9.0 llvmlite-0.41.1 more-itertools-10.5.0 mpmath-1.3.0 networkx-3.1 numba-0.58.1 openai-whisper-20240930 regex-2024.9.11 sympy-1.13.3 tiktoken-0.7.0 torch-2.2.2 tqdm-4.66.5\r\n",
      "The operation couldnâ€™t be completed. Unable to locate a Java Runtime that supports apt.\r\n",
      "Please visit http://www.java.com for information on installing Java.\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load audio",
   "id": "2e44cfe2f556cba1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:40:21.648372Z",
     "start_time": "2024-10-19T15:40:21.624980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "def transcribe_audio(ogg_file):\n",
    "    # Generate the .txt file using whisper\n",
    "    txt_file = ogg_file.replace('.ogg', '.txt')\n",
    "    subprocess.run(['whisper', ogg_file, '--model', 'tiny', '--language', 'en'], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    # Read and print the content of the generated .txt file\n",
    "    with open(txt_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        print(content)\n",
    "        "
   ],
   "id": "7016989925bb1a58",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:37:41.550829Z",
     "start_time": "2024-10-19T15:37:40.287161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "TELEGRAM_TOKEN = os.getenv(\"TELEGRAM_TOKEN\")\n",
    "base_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}\"\n",
    "\n",
    "# Step 1: Get updates and extract file_id for voice messages\n",
    "get_updates_url = f\"{base_url}/getUpdates\"\n",
    "parameters = {\"offset\": \"100\"}\n",
    "resp = requests.get(get_updates_url, params=parameters)\n",
    "updates = resp.json()\n",
    "\n",
    "# Iterate through updates to find voice messages\n",
    "cnt = 0\n",
    "for update in updates['result']:\n",
    "    if 'voice' in update['message']:\n",
    "        file_id = update['message']['voice']['file_id']\n",
    "        print(f\"file_id: {file_id}\")\n",
    "\n",
    "        # Step 2: Get file path\n",
    "        get_file_url = f\"{base_url}/getFile\"\n",
    "        file_params = {\"file_id\": file_id}\n",
    "        file_resp = requests.get(get_file_url, params=file_params)\n",
    "        file_path = file_resp.json()['result']['file_path']\n",
    "\n",
    "        # Step 3: Download the file\n",
    "        file_url = f\"https://api.telegram.org/file/bot{TELEGRAM_TOKEN}/{file_path}\"\n",
    "        voice_file = requests.get(file_url)\n",
    "\n",
    "        # Save the file\n",
    "        output = 'voice_' + str(cnt) + '.ogg'\n",
    "        with open(output, 'wb') as f:\n",
    "            f.write(voice_file.content)\n",
    "\n",
    "        cnt += 1\n",
    "        print(\"Voice message downloaded successfully.\")"
   ],
   "id": "5a4b1bd096328a7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_id: AwACAgQAAxkBAAMFZxO_Pc2cZRDsiDyx8ESws5Z3QjIAAgQfAAKpZaFQZaMwyS0j4442BA\n",
      "Voice message downloaded successfully.\n",
      "file_id: AwACAgQAAxkBAAMIZxPOa3twVEYdSuQv7_BeFmfDSS8AAlQfAAKpZaFQO3JCXBrogQw2BA\n",
      "Voice message downloaded successfully.\n",
      "file_id: AwACAgQAAxkBAAMJZxPOcHD9l3ubhevppFv26DREV-MAAlUfAAKpZaFQ5ISIDEYf0Xw2BA\n",
      "Voice message downloaded successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:42:00.985602Z",
     "start_time": "2024-10-19T15:40:32.846026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TELEGRAM_TOKEN = os.getenv(\"TELEGRAM_TOKEN\")\n",
    "base_url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}\"\n",
    "\n",
    "# Step 1: Get updates\n",
    "get_updates_url = f\"{base_url}/getUpdates\"\n",
    "parameters = {\"offset\": \"100\"}\n",
    "resp = requests.get(get_updates_url, params=parameters)\n",
    "updates = resp.json()\n",
    "\n",
    "# Step 2: Count voice messages\n",
    "voice_count = 0\n",
    "for update in updates['result']:\n",
    "    if 'voice' in update['message']:\n",
    "        voice_count += 1\n",
    "\n",
    "print(f\"Number of voice messages: {voice_count}\")\n",
    "\n",
    "# Transcribe all voice_cnt.ogg files\n",
    "for cnt in range(voice_count):  # Replace voice_count with the actual number of voice files\n",
    "    file_name = f'voice_{cnt}.ogg'\n",
    "    if os.path.exists(file_name):\n",
    "        transcribe_audio(file_name)\n",
    "    else:\n",
    "        print(f\"File {file_name} does not exist.\")"
   ],
   "id": "fbcd3b8fd9b9429e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of voice messages: 3\n",
      "Hello\n",
      "\n",
      "Hello, too\n",
      "\n",
      "Hello, it's me.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
